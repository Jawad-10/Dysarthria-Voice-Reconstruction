{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b790e225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28 in c:\\users\\mianj\\anaconda3\\lib\\site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\mianj\\anaconda3\\lib\\site-packages (from openai==0.28) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mianj\\anaconda3\\lib\\site-packages (from openai==0.28) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\mianj\\anaconda3\\lib\\site-packages (from openai==0.28) (3.8.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mianj\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mianj\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mianj\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mianj\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mianj\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mianj\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\mianj\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\mianj\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mianj\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mianj\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mianj\\anaconda3\\lib\\site-packages (from tqdm->openai==0.28) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11eb90ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyaudio\n",
      "  Obtaining dependency information for pyaudio from https://files.pythonhosted.org/packages/82/d8/f043c854aad450a76e476b0cf9cda1956419e1dacf1062eb9df3c0055abe/PyAudio-0.2.14-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading PyAudio-0.2.14-cp311-cp311-win_amd64.whl.metadata (2.7 kB)\n",
      "Downloading PyAudio-0.2.14-cp311-cp311-win_amd64.whl (164 kB)\n",
      "   ---------------------------------------- 0.0/164.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/164.1 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/164.1 kB ? eta -:--:--\n",
      "   --------- ----------------------------- 41.0/164.1 kB 487.6 kB/s eta 0:00:01\n",
      "   ----------------- --------------------- 71.7/164.1 kB 653.6 kB/s eta 0:00:01\n",
      "   ----------------- --------------------- 71.7/164.1 kB 653.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- 164.1/164.1 kB 979.8 kB/s eta 0:00:00\n",
      "Installing collected packages: pyaudio\n",
      "Successfully installed pyaudio-0.2.14\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "#pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8c6d621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gtts in c:\\users\\mianj\\anaconda3\\lib\\site-packages (2.5.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\mianj\\anaconda3\\lib\\site-packages (from gtts) (2.31.0)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in c:\\users\\mianj\\anaconda3\\lib\\site-packages (from gtts) (8.1.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\mianj\\anaconda3\\lib\\site-packages (from click<8.2,>=7.1->gtts) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mianj\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gtts) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mianj\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gtts) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mianj\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gtts) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mianj\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gtts) (2023.7.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "#pip install gtts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "defef4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import io\n",
    "import tempfile\n",
    "import pyaudio\n",
    "import wave\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79b99499",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acafb02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File address stored in a variable\n",
    "file_path = r\"D:\\dys\\Module 2\\Disarthria-20240315T142530Z-001\\Disarthria\\Backspace\\F02_B1_C2_M4.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8042b723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Back...space...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(file_path, \"rb\") as audio_file:\n",
    "    # Transcribe the audio\n",
    "    transcript = openai.Audio.transcribe(\n",
    "        file=audio_file,\n",
    "        model=\"whisper-1\",\n",
    "        response_format=\"text\",\n",
    "        language=\"en\"\n",
    "    )\n",
    "\n",
    "print(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "730dfd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Finished recording.\n"
     ]
    }
   ],
   "source": [
    "# Define a function to record live voice using microphone\n",
    "def record_audio(duration=5, output_file=\"temp.wav\"):\n",
    "    CHUNK = 1024\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 1\n",
    "    RATE = 44100\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    print(\"Recording...\")\n",
    "\n",
    "    for i in range(0, int(RATE / CHUNK * duration)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Finished recording.\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    # Save recorded audio to a WAV file\n",
    "    wf = wave.open(output_file, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "# Define a function to transcribe audio using OpenAI API\n",
    "def transcribe_audio(audio_file):\n",
    "    with open(audio_file, \"rb\") as f:\n",
    "        response = openai.Audio.transcribe(\n",
    "            file=f,\n",
    "            model=\"whisper-1\",\n",
    "            response_format=\"text\",\n",
    "            language=\"en\"\n",
    "        )\n",
    "    return response\n",
    "\n",
    "# Record audio for 5 seconds\n",
    "recorded_file = \"temp.wav\"\n",
    "record_audio(duration=10, output_file=recorded_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32dc87f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Incorrect API key provided: sk-TYLPK***************************************wv45. You can find your API key at https://platform.openai.com/account/api-keys.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Transcribe the recorded audio\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m transcription \u001b[38;5;241m=\u001b[39m transcribe_audio(recorded_file)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranscription:\u001b[39m\u001b[38;5;124m\"\u001b[39m, transcription)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Remove the temporary audio file\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[28], line 41\u001b[0m, in \u001b[0;36mtranscribe_audio\u001b[1;34m(audio_file)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranscribe_audio\u001b[39m(audio_file):\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(audio_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 41\u001b[0m         response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mAudio\u001b[38;5;241m.\u001b[39mtranscribe(\n\u001b[0;32m     42\u001b[0m             file\u001b[38;5;241m=\u001b[39mf,\n\u001b[0;32m     43\u001b[0m             model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhisper-1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     44\u001b[0m             response_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     45\u001b[0m             language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     46\u001b[0m         )\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\api_resources\\audio.py:67\u001b[0m, in \u001b[0;36mAudio.transcribe\u001b[1;34m(cls, model, file, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[0;32m     55\u001b[0m requestor, files, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[0;32m     56\u001b[0m     file\u001b[38;5;241m=\u001b[39mfile,\n\u001b[0;32m     57\u001b[0m     filename\u001b[38;5;241m=\u001b[39mfile\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m     65\u001b[0m )\n\u001b[0;32m     66\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_url(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranscriptions\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 67\u001b[0m response, _, api_key \u001b[38;5;241m=\u001b[39m requestor\u001b[38;5;241m.\u001b[39mrequest(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, files\u001b[38;5;241m=\u001b[39mfiles, params\u001b[38;5;241m=\u001b[39mdata)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m util\u001b[38;5;241m.\u001b[39mconvert_to_openai_object(\n\u001b[0;32m     69\u001b[0m     response, api_key, api_version, organization\n\u001b[0;32m     70\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response(result, stream)\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    701\u001b[0m             result\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    702\u001b[0m             result\u001b[38;5;241m.\u001b[39mstatus_code,\n\u001b[0;32m    703\u001b[0m             result\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    704\u001b[0m             stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    705\u001b[0m         ),\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    763\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 765\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    766\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    767\u001b[0m     )\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: Incorrect API key provided: sk-TYLPK***************************************wv45. You can find your API key at https://platform.openai.com/account/api-keys."
     ]
    }
   ],
   "source": [
    "# Transcribe the recorded audio\n",
    "transcription = transcribe_audio(recorded_file)\n",
    "print(\"Transcription:\", transcription)\n",
    "\n",
    "# Remove the temporary audio file\n",
    "os.remove(recorded_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43105cfc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transcript' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming you already have the 'transcript' variable containing the text\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m text_to_speak \u001b[38;5;241m=\u001b[39m transcript\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Provide the language (optional)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m language \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transcript' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming you already have the 'transcript' variable containing the text\n",
    "text_to_speak = transcript\n",
    "\n",
    "# Provide the language (optional)\n",
    "language = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b78f68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features\n",
    "def extract_features(audio_file):\n",
    "    y, sr = librosa.load(audio_file, sr=None)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    delta = librosa.feature.delta(mfccs)\n",
    "    delta_delta = librosa.feature.delta(mfccs, order=2)\n",
    "    return mfccs, delta, delta_delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f31aafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "dysarthric_audio_file = r'D:\\dys\\Dysarthria and Non Dysarthria\\Dataset\\Female_dysarthria\\F01\\Session1\\Wav\\0008.wav'\n",
    "normal_audio_file = r'D:\\dys\\Dysarthria and Non Dysarthria\\Dataset\\Female_Non_Dysarthria\\FC01\\Session1\\Wav\\0030.wav'\n",
    "\n",
    "# Extract features for dysarthric and normal voices\n",
    "dysarthric_mfccs, dysarthric_delta, dysarthric_delta_delta = extract_features(dysarthric_audio_file)\n",
    "normal_mfccs, normal_delta, normal_delta_delta = extract_features(normal_audio_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939f758b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2774f223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b90ca7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d873ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "10f454c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dysarthria(text):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"\"\"You are given the automatic speech \n",
    "recognition result of a speaker with dysarthria, \n",
    "which may contain errors due to inaccurate \n",
    "pronunciation. Remove the speech recognition \n",
    "errors and correct the sentence. Only respond with \n",
    "the corrected results, without mentioning the instruction.\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"Analyze the following text and make nearly correct sentence or word if sentence or word make sense dont change give same word: {text} \"\"\"}\n",
    "    ]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages = messages,\n",
    "    \n",
    "    \n",
    "    stop=None,\n",
    "    temperature=0.3)\n",
    "\n",
    "    response_text=response.choices[0].message.content.strip().lower()\n",
    "\n",
    "    return response_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c7716e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "okay, ma'am. my baby ate a cupcake on the train. okay, she's repeating. my baby ate a cupcake on the train. say it one more time. my baby ate a cupcake on the train. okay, can you say west register street? west register street. okay, say riding artillery brigade. riding artillery brigade. okay, tell me what the weather's like outside. the weather is very hot and humid. okay, all right. thank you very much.\n"
     ]
    }
   ],
   "source": [
    "input = transcript\n",
    "response = dysarthria(transcript)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "167b31d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c442c57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you already have the 'transcript' variable containing the text\n",
    "text_to_speak = transcript\n",
    "\n",
    "# Provide the language (optional)\n",
    "language = 'en'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c19ad6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Provide the file name for the generated audio file\n",
    "output_file = 'output_audio.mp3'\n",
    "\n",
    "# Initialize the gTTS object with the text and language\n",
    "tts = gTTS(text=text_to_speak, lang=language, slow=False)\n",
    "\n",
    "# Save the generated speech to a file\n",
    "tts.save(output_file)\n",
    "\n",
    "# Play the audio file\n",
    "os.system(f'start {output_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f78e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d576d517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27e91af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d963afde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1dc4e61b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43015854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7641f911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a6110b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1938e8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
